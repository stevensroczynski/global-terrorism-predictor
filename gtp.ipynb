{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Terrorism Attribution Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and field variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Global Terrorism Database from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtd.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files(\"START-UMD/gtd\", quiet=False, path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols=[\"iyear\",\n",
    "         \"suicide\",\n",
    "         \"imonth\",\n",
    "         \"country\",\n",
    "         \"region\",\n",
    "         \"provstate\",\n",
    "         \"city\",\n",
    "         \"alternative\",\n",
    "         \"attacktype1\",\n",
    "         \"targtype1\",\n",
    "         \"natlty1\",\n",
    "         \"gname\",\n",
    "         \"weaptype1\",\n",
    "         \"ransom\"]\n",
    "\n",
    "data = pd.read_csv(data_path + \"/gtd.zip\",\n",
    "                        encoding = \"ISO-8859-1\",\n",
    "                        compression='zip',\n",
    "                        usecols=usecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set dTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(data.dropna())\n",
    "# data = data.fillna(value={0})\n",
    "data['alternative'] = data.alternative.astype('category')\n",
    "data['suicide'] = data.suicide.astype('category')\n",
    "data['iyear'] = data.iyear.astype('category')\n",
    "data['imonth'] = data.imonth.astype('category')\n",
    "data['country'] = data.country.astype('category')\n",
    "data['region'] = data.region.astype('category')\n",
    "data['provstate'] = data.provstate.astype('str').astype('category')\n",
    "data['city'] = data.city.astype('str').astype('category')\n",
    "data['attacktype1'] = data.attacktype1.astype('category')\n",
    "data['targtype1'] = data.targtype1.astype('category')\n",
    "data['natlty1'] = data.natlty1.astype('category')\n",
    "data['weaptype1'] = data.weaptype1.astype('category')\n",
    "data['ransom'] = data.ransom.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out unattributed attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributed = data.loc[data['gname'] != \"Unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributed = attributed.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fit = attributed.select_dtypes(include=['object'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "attributed = attributed.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a copy of the attributeddataframe which does not contain the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98909, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_vars = attributed.copy()\n",
    "independent_vars = independent_vars[independent_vars.columns.drop(list(independent_vars.filter(regex='gname')))]\n",
    "independent_vars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dataframe with of the dependent variables (organizations to which the attacks were attribued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98909, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_vars = pd.DataFrame(attributed.loc[:,list(attributed.filter(regex='gname'))])\n",
    "dependent_vars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "independant_size = independent_vars.shape\n",
    "dependant_size = dependent_vars.shape\n",
    "if independant_size[0] != dependant_size[0]:\n",
    "    raise ValueError('Independent and Dependant DFs do not match')\n",
    "\n",
    "split_size = int(independant_size[0] * 0.7)\n",
    "\n",
    "training_independant_vars = independent_vars.iloc[:split_size]\n",
    "test_independant_vars = independent_vars.iloc[split_size:]\n",
    "\n",
    "training_dependant_vars = dependent_vars.iloc[:split_size]\n",
    "test_dependant_vars = dependent_vars.iloc[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 35\n",
      "building tree 3 of 35\n",
      "building tree 4 of 35\n",
      "building tree 5 of 35\n",
      "building tree 6 of 35\n",
      "building tree 7 of 35\n",
      "building tree 8 of 35\n",
      "building tree 9 of 35\n",
      "building tree 10 of 35\n",
      "building tree 11 of 35\n",
      "building tree 12 of 35\n",
      "building tree 13 of 35\n",
      "building tree 14 of 35\n",
      "building tree 15 of 35\n",
      "building tree 16 of 35\n",
      "building tree 17 of 35\n",
      "building tree 18 of 35\n",
      "building tree 19 of 35\n",
      "building tree 20 of 35\n",
      "building tree 21 of 35\n",
      "building tree 22 of 35\n",
      "building tree 23 of 35\n",
      "building tree 24 of 35\n",
      "building tree 25 of 35\n",
      "building tree 26 of 35\n",
      "building tree 27 of 35\n",
      "building tree 28 of 35\n",
      "building tree 29 of 35\n",
      "building tree 30 of 35\n",
      "building tree 31 of 35\n",
      "building tree 32 of 35\n",
      "building tree 33 of 35\n",
      "building tree 34 of 35\n",
      "building tree 35 of 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 76.13655511744683%\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(verbose=2, n_estimators=35, warm_start=True)\n",
    "classifier.fit(training_independant_vars, training_dependant_vars.values.ravel())\n",
    "predictions = classifier.predict(test_independant_vars)\n",
    "total = accuracy_score(test_dependant_vars, predictions)\n",
    "print(\"Accuracy is {}%\".format(total * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Confusion Matrix (Currently computing an unwieldingly large CM). TODO: Believe I need to implement this as a One vs. All CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 2128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "import numpy as np\n",
    "cnf_matrix = confusion_matrix(test_dependant_vars, predictions)\n",
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Confusion Matrix. (Currently, the CM is too large and will cause the kernal to hang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "import itertools\n",
    "class_names = test_independant_vars.columns\n",
    "# plot_confusion_matrix(np.array(cnf_matrix), class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
